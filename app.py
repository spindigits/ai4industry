import os
import streamlit as st
from pathlib import Path
from dotenv import load_dotenv

from src.core.hybrid_rag import QueryExamples
from src.ui.dashboard import render_dashboard
from src.services.rag_init import init_components, load_and_index_documents
from src.ui.styles import apply_custom_styles

# Configuration
load_dotenv()

MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
QDRANT_ENDPOINT = os.getenv("QDRANT_ENDPOINT")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = "documents_rag"

def main():
    st.set_page_config(
        page_title="GROUPE 1 - RAG UI",
        layout="wide",
        page_icon="ü§ñ",
        initial_sidebar_state="expanded"
    )

    # Appliquer le styles
    apply_custom_styles()

    # En-t√™te
    st.title("GROUPE 1 - RAG UI")
    st.markdown("""
        <p style='font-size: 1.2rem; color: #64748b; margin-bottom: 2rem;'>
            RAG intelligent - recherche vectorielle et graphique
        </p>
    """, unsafe_allow_html=True)

    # Initialisation
    qdrant_client, embeddings, llm, hybrid_rag = init_components(
        MISTRAL_API_KEY, QDRANT_ENDPOINT, QDRANT_API_KEY
    )


    # Chargement automatique Neo4j (une seule fois par session)
    #if "neo4j_initialized" not in st.session_state:
    #   st.toast("‚è≥ Start loading Neo4j Graph...", icon="‚è≥")
    #   with st.spinner("Initialisation de la base de donn√©es Neo4j..."):
    #       from src.services.neo4j_loader import Neo4jLoader
    #       loader = Neo4jLoader()
    #       try:
    #           loader.load_all()
    #           st.session_state["neo4j_initialized"] = True
    #           st.toast("‚úÖ Neo4j Graph ready!", icon="‚úÖ")
    #       except Exception as e:
    #           st.error(f"Erreur chargement Neo4j: {e}")
    #       finally:
    #           loader.close()

    # Sidebar
    with st.sidebar:
        st.markdown("### üì§ Importer des documents")
        st.markdown("""
            <div style='background: rgba(59, 130, 246, 0.1); padding: 0.5rem; border-radius: 6px; margin-bottom: 0.75rem; font-size: 0.85rem;'>
                üí° Glissez-d√©posez vos fichiers ci-dessous
            </div>
        """, unsafe_allow_html=True)

        uploaded_files = st.file_uploader(
            "Choisissez des fichiers",
            type=['txt', 'json', 'csv', 'pdf', 'png', 'jpg', 'jpeg'],
            accept_multiple_files=True,
            help="Formats support√©s: TXT, JSON, CSV, PDF, PNG, JPG, JPEG",
            label_visibility="collapsed"
        )

        if uploaded_files:
            st.markdown(f"**{len(uploaded_files)} fichier(s) s√©lectionn√©(s)**")

            if st.button("üì• Sauvegarder et indexer", use_container_width=True, type="primary"):
                data_dir = Path("data")
                data_dir.mkdir(exist_ok=True)

                success_count = 0
                error_count = 0

                with st.spinner("üíæ Sauvegarde en cours..."):
                    for uploaded_file in uploaded_files:
                        try:
                            file_path = data_dir / uploaded_file.name
                            with open(file_path, "wb") as f:
                                f.write(uploaded_file.getbuffer())
                            success_count += 1
                        except Exception as e:
                            st.error(f"‚ùå Erreur pour {uploaded_file.name}: {e}")
                            error_count += 1

                if success_count > 0:
                    st.success(f"‚úÖ {success_count} fichier(s) sauvegard√©(s)!")
                    st.info("üîÑ Rechargez la page pour indexer les nouveaux documents")

                    if st.button("üîÑ Recharger maintenant", use_container_width=True):
                        st.cache_resource.clear()
                        st.rerun()

                if error_count > 0:
                    st.warning(f"‚ö†Ô∏è {error_count} erreur(s) rencontr√©e(s)")

        st.divider()

        st.markdown("### üîß Admin")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üóëÔ∏è Reset Neo4j", use_container_width=True, help="Vider la base Neo4j"):
                with st.spinner("Nettoyage de Neo4j..."):
                    from src.services.neo4j_loader import Neo4jLoader
                    loader = Neo4jLoader()
                    try:
                        loader.clear_database()
                        st.success("‚úÖ Neo4j vid√© !")
                    except Exception as e:
                        st.error(f"Erreur: {e}")
                    finally:
                        loader.close()
            if st.button("üîß Charger Neo4j", use_container_width=True, help="Charger la base Neo4j"):
                st.toast("‚è≥ Start loading Neo4j Graph...", icon="‚è≥")
                with st.spinner("Initialisation de la base de donn√©es Neo4j..."):
                    from src.services.neo4j_loader import Neo4jLoader
                    loader = Neo4jLoader()
                    try:
                        loader.load_all()
                        st.session_state["neo4j_initialized"] = True
                        st.toast("‚úÖ Neo4j Graph ready!", icon="‚úÖ")
                    except Exception as e:
                        st.error(f"Erreur chargement Neo4j: {e}")
                    finally:
                        loader.close()

        with col2:
            if st.button("üóëÔ∏è Reset Qdrant", use_container_width=True, help="R√©initialise la collection Qdrant"):
                try:
                    qdrant_client.delete_collection(COLLECTION_NAME)
                    st.cache_resource.clear()
                    st.success("‚úÖ Qdrant vid√©")
                    st.rerun()
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur: {e}")

        st.divider()

        st.markdown("### üß† Mod√®le de Raisonnement")
        # Liste des mod√®les disponibles
        available_models = ["mistral-small-latest", "mistral-large-latest", "pixtral-12b-2409"]
        
        # S√©lecteur
        selected_model = st.selectbox(
            "Choisir le LLM:",
            available_models,
            index=0,
            help="Le mod√®le utilis√© pour g√©n√©rer les r√©ponses finales"
        )

        # Mise √† jour dynamique du mod√®le si changement
        if "current_model" not in st.session_state:
            st.session_state["current_model"] = selected_model
        
        if st.session_state["current_model"] != selected_model:
            hybrid_rag.set_model(selected_model)
            st.session_state["current_model"] = selected_model
            st.toast(f"ü§ñ Mod√®le chang√© pour {selected_model}")

        st.divider()

        st.markdown("### üë• Cr√©dits")
        st.markdown("""
            <div style='font-size: 0.9rem; color: #64748b;'>
                <strong>D√©velopp√© par le groupe 1:</strong><br>
                ‚Ä¢ Enzo<br>
                ‚Ä¢ Kyllian<br>
                ‚Ä¢ Romain<br>
                ‚Ä¢ Will<br>
                ‚Ä¢ Yov√®n
            </div>
        """, unsafe_allow_html=True)

    # Chargement et indexation
    with st.spinner("‚è≥ Chargement et indexation des documents..."):
        vector_store, num_chunks = load_and_index_documents(
            qdrant_client, embeddings, COLLECTION_NAME, QDRANT_ENDPOINT, QDRANT_API_KEY, MISTRAL_API_KEY
        )

    if vector_store is None:
        st.markdown("""
            <div style='background: rgba(251, 191, 36, 0.2); padding: 1rem; border-radius: 8px; border-left: 4px solid #fbbf24; margin: 1rem 0;'>
                ‚ö†Ô∏è <strong>Aucun document trouv√©</strong><br>
                Veuillez ajouter des documents dans le dossier <code>data/</code>
            </div>
        """, unsafe_allow_html=True)
        st.info("üìù Formats support√©s: .txt, .json, .csv, .pdf")
        return

    # Tabs
    tab_router, tab_dashboard = st.tabs([
        "üß≠ ChatBOT",
        "üìä Dashboard M√©triques"
    ])

    # TAB 1: Routeur intelligent
    with tab_router:
        st.markdown("### üß≠ CHAT BOT")

        with st.form("chat_form"):
            question_auto = st.text_input(
                "üí¨ Posez votre question:",
                placeholder="Posez n'importe quelle question...",
                key="auto",
                help="Le syst√®me analysera votre question et choisira automatiquement la meilleure strat√©gie"
            )
            submitted = st.form_submit_button("Envoyer", type="primary")
        
        if submitted and question_auto:
            # Analyse rapide (sans explication d√©taill√©e visuelle)
            routing = hybrid_rag.explain_routing(question_auto)
            if routing['strategy'] == "multi_hop":
                strategy_display = "üß† Mode Multi-Hop (Graph + Vector)"
            elif routing['strategy'] == "visual":
                strategy_display = "üñºÔ∏è Mode Visuel (Pixtral)"
            else:
                strategy_display = "üîé Mode Simple (Vector)"
            
            st.markdown(f"""
                <div style='margin-bottom: 1rem; color: #64748b; font-size: 0.9rem;'>
                    M√©thode utilis√©e: <strong>{strategy_display}</strong>
                </div>
            """, unsafe_allow_html=True)

            with st.spinner("ü§ñ Traitement intelligent de la question..."):
                result = hybrid_rag.query(question_auto, vector_store)
                # Stocker le temps d'ex√©cution pour le dashboard
                if "execution_time_ms" in result:
                    st.session_state["last_llm_time"] = result["execution_time_ms"]

            st.markdown("---")
            st.markdown("### ‚ú® R√©ponse")
            st.markdown(f"""
                <div style='background: rgba(239, 68, 68, 0.05); padding: 1.5rem; border-radius: 8px; margin: 1rem 0; font-size: 1.05rem; line-height: 1.6;'>
                    {result["answer"]}
                </div>
            """, unsafe_allow_html=True)

            st.markdown("### üìä Sources consult√©es")
            
            source_tab_vector, source_tab_graph = st.tabs(["üìö Documents (Qdrant)", "üï∏Ô∏è Relations (Neo4j)"])
            
            # --- TAB VECTOR ---
            with source_tab_vector:
                if result["sources"]["vector_docs"]:
                    st.caption(f"**{len(result['sources']['vector_docs'])}** documents pertinents trouv√©s")
                    
                    # Layout en grille (3 colonnes)
                    cols = st.columns(3)
                    
                    for i, doc in enumerate(result["sources"]["vector_docs"]):
                        source_name = doc.metadata.get('source', 'Inconnu')
                        display_name = Path(source_name).name
                        doc_type = doc.metadata.get('type', 'unknown')
                        
                        # Ic√¥ne selon le type
                        icon = "üìÑ"
                        if doc_type == 'pdf': icon = "üìï"
                        elif doc_type == 'json': icon = "üìã"
                        elif doc_type == 'csv': icon = "üìä"
                        elif doc_type == 'image': icon = "üñºÔ∏è"
                        elif doc_type == 'visual': icon = "üëÅÔ∏è"
                        
                        # Distribution dans les colonnes
                        with cols[i % 3]:
                            with st.container(border=True):
                                st.markdown(f"**{icon} Source {i+1}**")
                                st.caption(f"_{display_name}_")
                                
                                # Aper√ßu court
                                preview = doc.page_content[:150].replace("\n", " ") + "..."
                                st.markdown(f"<div style='font-size: 0.85em; color: #cbd5e1; margin-bottom: 10px;'>{preview}</div>", unsafe_allow_html=True)
                                
                                # D√©tails complets dans un expander
                                with st.expander("üîé Voir d√©tails"):
                                    st.markdown("**Contenu complet:**")
                                    st.code(doc.page_content, language="text")
                                    st.markdown("**M√©tadonn√©es:**")
                                    st.json(doc.metadata)

                else:
                    st.info("Aucun document vectoriel utilis√©.")

            # --- TAB GRAPH ---
            with source_tab_graph:
                graph_ctx = result["sources"].get("graph_context", [])
                if graph_ctx and result["strategy"] in ["multi_hop", "hybrid"]:
                    st.caption(f"**{len(graph_ctx)}** √©tapes de raisonnement graphique")
                    
                    # Layout en grille (3 colonnes)
                    cols = st.columns(3)

                    for idx, item in enumerate(graph_ctx):
                        query_type = item['query_type']
                        results = item.get("results", [])
                        
                        # Distribution dans les colonnes
                        with cols[idx % 3]:
                            with st.container(border=True):
                                st.markdown(f"**üï∏Ô∏è √âtape {idx + 1}**")
                                st.caption(f"_{query_type}_")
                                
                                # Aper√ßu des r√©sultats
                                if results:
                                    num_res = len(results)
                                    first_res = str(results[0])[:100] + "..."
                                    st.markdown(f"<div style='font-size: 0.85em; color: #cbd5e1; margin-bottom: 5px;'>{num_res} r√©sultat(s)</div>", unsafe_allow_html=True)
                                    st.markdown(f"<div style='font-size: 0.8em; color: #94a3b8; margin-bottom: 10px; font-style: italic;'>Ex: {first_res}</div>", unsafe_allow_html=True)
                                else:
                                    st.info("Aucun r√©sultat direct")

                                # D√©tails complets dans un expander
                                with st.expander("üîé Voir les donn√©es"):
                                    st.markdown(f"**Requ√™te:** `{query_type}`")
                                    if results:
                                        for res in results:
                                            st.code(str(res), language="json")
                                    else:
                                        st.warning("Aucune donn√©e retourn√©e par le graphe.")
                else:
                    st.info("Le graphe Neo4j n'a pas √©t√© sollicit√© pour cette r√©ponse (Mode Simple).")

    # TAB 2: Dashboard M√©triques
    with tab_dashboard:
        render_dashboard(qdrant_client, hybrid_rag.neo4j_querier, vector_store)

if __name__ == "__main__":
    main()