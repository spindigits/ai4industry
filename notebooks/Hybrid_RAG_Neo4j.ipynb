{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RAG System with Neo4j & Qdrant\n",
    "\n",
    "Ce notebook impl\u00e9mente un syst\u00e8me RAG Hybride combinant :\n",
    "1. **Vector Search** avec Qdrant (pour la recherche s\u00e9mantique de texte)\n",
    "2. **Graph Search** avec Neo4j (pour les relations et entit\u00e9s)\n",
    "3. **LLM** Groq (Llama 3) pour la g\u00e9n\u00e9ration\n",
    "\n",
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, CSVLoader, JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Neo4j imports\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv(\"../.env\")  # On remonte d'un niveau car le notebook est dans /notebooks\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classe Neo4jConnection\n",
    "Cette classe g\u00e8re la connexion bas niveau avec la base de donn\u00e9es Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jConnection:\n",
    "    \"\"\"Manages Neo4j database connection and operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, uri: str, user: str = None, password: str = None, \n",
    "                 client_id: str = None, client_secret: str = None):\n",
    "        self.uri = uri\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.driver = None\n",
    "        self._connect()\n",
    "    \n",
    "    def _connect(self):\n",
    "        \"\"\"Establish connection to Neo4j database.\"\"\"\n",
    "        try:\n",
    "            # Try OAuth2 / Bearer token auth first (for Neo4j Aura with API credentials)\n",
    "            if self.client_id and self.client_secret:\n",
    "                from neo4j import bearer_auth\n",
    "                # For Neo4j Aura, client credentials can be used as bearer auth\n",
    "                auth = bearer_auth(self.client_secret)\n",
    "                self.driver = GraphDatabase.driver(self.uri, auth=auth)\n",
    "            else:\n",
    "                # Standard basic authentication\n",
    "                self.driver = GraphDatabase.driver(self.uri, auth=(self.user, self.password))\n",
    "            \n",
    "            # Test connection\n",
    "            self.driver.verify_connectivity()\n",
    "            print(f\"\u2705 Connected to Neo4j at {self.uri}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\u26a0\ufe0f Failed to connect to Neo4j: {e}\")\n",
    "            self.driver = None\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the database connection.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "    \n",
    "    def is_connected(self) -> bool:\n",
    "        \"\"\"Check if connected to Neo4j.\"\"\"\n",
    "        return self.driver is not None\n",
    "    \n",
    "    def execute_query(self, query: str, parameters: Dict = None) -> List[Dict]:\n",
    "        \"\"\"Execute a Cypher query and return results.\"\"\"\n",
    "        if not self.driver:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(query, parameters or {})\n",
    "                return [record.data() for record in result]\n",
    "        except Exception as e:\n",
    "            print(f\"Query error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_node(self, label: str, properties: Dict) -> Optional[int]:\n",
    "        \"\"\"Create a node with given label and properties.\"\"\"\n",
    "        query = f\"CREATE (n:{label} $props) RETURN id(n) as node_id\"\n",
    "        result = self.execute_query(query, {\"props\": properties})\n",
    "        return result[0][\"node_id\"] if result else None\n",
    "    \n",
    "    def create_relationship(self, from_id: int, to_id: int, rel_type: str, properties: Dict = None):\n",
    "        \"\"\"Create a relationship between two nodes.\"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH (a), (b)\n",
    "        WHERE id(a) = $from_id AND id(b) = $to_id\n",
    "        CREATE (a)-[r:%s $props]->(b)\n",
    "        RETURN type(r) as rel_type\n",
    "        \"\"\" % rel_type\n",
    "        return self.execute_query(query, {\"from_id\": from_id, \"to_id\": to_id, \"props\": properties or {}})\n",
    "    \n",
    "    def search_nodes(self, keyword: str, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Search nodes by keyword in their properties.\"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE any(key IN keys(n) WHERE toString(n[key]) CONTAINS $keyword)\n",
    "        RETURN n, labels(n) as labels, id(n) as node_id\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "        return self.execute_query(query, {\"keyword\": keyword, \"limit\": limit})\n",
    "    \n",
    "    def get_node_relationships(self, node_id: int, depth: int = 2) -> List[Dict]:\n",
    "        \"\"\"Get all relationships for a node up to specified depth.\"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH path = (n)-[*1..%d]-(m)\n",
    "        WHERE id(n) = $node_id\n",
    "        RETURN \n",
    "            [rel in relationships(path) | {type: type(rel), props: properties(rel)}] as relationships,\n",
    "            [node in nodes(path) | {id: id(node), labels: labels(node), props: properties(node)}] as nodes\n",
    "        LIMIT 50\n",
    "        \"\"\" % depth\n",
    "        return self.execute_query(query, {\"node_id\": node_id})\n",
    "    \n",
    "    def clear_graph(self):\n",
    "        \"\"\"Clear all nodes and relationships (use with caution!).\"\"\"\n",
    "        self.execute_query(\"MATCH (n) DETACH DELETE n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classe GraphRAG\n",
    "Cette classe utilise le LLM pour extraire des entit\u00e9s et relations du texte, puis interroge le graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRAG:\n",
    "    \"\"\"Graph-based RAG using Neo4j for knowledge graph storage and retrieval.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm=None):\n",
    "        self.neo4j_uri = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "        self.neo4j_user = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "        self.neo4j_password = os.getenv(\"NEO4J_PASSWORD\", \"\")\n",
    "        self.neo4j_client_id = os.getenv(\"NEO4J_CLIENT_ID\", \"\")\n",
    "        self.neo4j_client_secret = os.getenv(\"NEO4J_CLIENT_SECRET\", \"\")\n",
    "        \n",
    "        self.neo4j = None\n",
    "        self.llm = llm\n",
    "        self._connect_neo4j()\n",
    "    \n",
    "    def _connect_neo4j(self):\n",
    "        \"\"\"Initialize Neo4j connection.\"\"\"\n",
    "        # Check if OAuth2 credentials are provided\n",
    "        has_oauth = (self.neo4j_client_id and self.neo4j_client_secret and \n",
    "                     \"your_client\" not in self.neo4j_client_id)\n",
    "        # Check if basic auth credentials are provided\n",
    "        has_basic_auth = (self.neo4j_password and \n",
    "                          \"your_neo4j_password\" not in self.neo4j_password)\n",
    "        \n",
    "        if has_oauth or has_basic_auth:\n",
    "            try:\n",
    "                self.neo4j = Neo4jConnection(\n",
    "                    uri=self.neo4j_uri,\n",
    "                    user=self.neo4j_user if has_basic_auth else None,\n",
    "                    password=self.neo4j_password if has_basic_auth else None,\n",
    "                    client_id=self.neo4j_client_id if has_oauth else None,\n",
    "                    client_secret=self.neo4j_client_secret if has_oauth else None\n",
    "                )\n",
    "                if not self.neo4j.is_connected():\n",
    "                    self.neo4j = None\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f Neo4j initialization failed: {e}\")\n",
    "                self.neo4j = None\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f Neo4j credentials not configured. GraphRAG will be disabled.\")\n",
    "    \n",
    "    def is_available(self) -> bool:\n",
    "        \"\"\"Check if GraphRAG is available.\"\"\"\n",
    "        return self.neo4j is not None and self.neo4j.is_connected()\n",
    "    \n",
    "    def extract_entities_and_relations(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Use LLM to extract entities and relationships from text.\"\"\"\n",
    "        if not self.llm:\n",
    "            return {\"entities\": [], \"relations\": []}\n",
    "        \n",
    "        extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an expert at extracting entities and relationships from text.\n",
    "Extract entities (people, organizations, concepts, locations, etc.) and relationships between them.\n",
    "\n",
    "Return your response as a valid JSON object with this structure:\n",
    "{\n",
    "    \"entities\": [\n",
    "        {\"name\": \"entity name\", \"type\": \"PERSON|ORGANIZATION|CONCEPT|LOCATION|PRODUCT|EVENT\", \"description\": \"brief description\"}\n",
    "    ],\n",
    "    \"relations\": [\n",
    "        {\"from\": \"entity1 name\", \"to\": \"entity2 name\", \"type\": \"RELATIONSHIP_TYPE\", \"description\": \"brief description\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Entity names should be normalized (proper capitalization, full names)\n",
    "- Relationship types should be uppercase with underscores (e.g., WORKS_FOR, LOCATED_IN, RELATED_TO)\n",
    "- Only extract clear, factual information\n",
    "- Return ONLY the JSON, no additional text\"\"\"),\n",
    "            (\"human\", \"Extract entities and relationships from this text:\\n\\n{text}\")\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            chain = extraction_prompt | self.llm | StrOutputParser()\n",
    "            response = chain.invoke({\"text\": text[:4000]})  # Limit text length\n",
    "            \n",
    "            # Parse JSON response\n",
    "            # Clean up response - remove markdown code blocks if present\n",
    "            cleaned = response.strip()\n",
    "            if cleaned.startswith(\"```\"):\n",
    "                cleaned = re.sub(r'^```(?:json)?\\s*', '', cleaned)\n",
    "                cleaned = re.sub(r'\\s*```$', '', cleaned)\n",
    "            \n",
    "            return json.loads(cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error: {e}\")\n",
    "            return {\"entities\": [], \"relations\": []}\n",
    "        except Exception as e:\n",
    "            print(f\"Entity extraction error: {e}\")\n",
    "            return {\"entities\": [], \"relations\": []}\n",
    "    \n",
    "    def build_graph(self, documents: List[Document]) -> Dict[str, int]:\n",
    "        \"\"\"Build knowledge graph from documents.\"\"\"\n",
    "        if not self.is_available():\n",
    "            return {\"entities\": 0, \"relations\": 0}\n",
    "        \n",
    "        total_entities = 0\n",
    "        total_relations = 0\n",
    "        entity_id_map = {}  # Maps entity names to Neo4j node IDs\n",
    "        \n",
    "        for doc in documents:\n",
    "            # Extract entities and relations\n",
    "            extracted = self.extract_entities_and_relations(doc.page_content)\n",
    "            \n",
    "            # Create entity nodes\n",
    "            for entity in extracted.get(\"entities\", []):\n",
    "                entity_name = entity.get(\"name\", \"\").strip()\n",
    "                if not entity_name:\n",
    "                    continue\n",
    "                    \n",
    "                # Check if entity already exists\n",
    "                if entity_name.lower() not in entity_id_map:\n",
    "                    node_id = self.neo4j.create_node(\n",
    "                        label=entity.get(\"type\", \"ENTITY\"),\n",
    "                        properties={\n",
    "                            \"name\": entity_name,\n",
    "                            \"description\": entity.get(\"description\", \"\"),\n",
    "                            \"source\": doc.metadata.get(\"source\", \"unknown\")\n",
    "                        }\n",
    "                    )\n",
    "                    if node_id is not None:\n",
    "                        entity_id_map[entity_name.lower()] = node_id\n",
    "                        total_entities += 1\n",
    "            \n",
    "            # Create relationships\n",
    "            for relation in extracted.get(\"relations\", []):\n",
    "                from_name = relation.get(\"from\", \"\").strip().lower()\n",
    "                to_name = relation.get(\"to\", \"\").strip().lower()\n",
    "                rel_type = relation.get(\"type\", \"RELATED_TO\").upper().replace(\" \", \"_\")\n",
    "                \n",
    "                if from_name in entity_id_map and to_name in entity_id_map:\n",
    "                    self.neo4j.create_relationship(\n",
    "                        from_id=entity_id_map[from_name],\n",
    "                        to_id=entity_id_map[to_name],\n",
    "                        rel_type=rel_type,\n",
    "                        properties={\"description\": relation.get(\"description\", \"\")}\n",
    "                    )\n",
    "                    total_relations += 1\n",
    "        \n",
    "        return {\"entities\": total_entities, \"relations\": total_relations}\n",
    "    \n",
    "    def query_graph(self, question: str) -> str:\n",
    "        \"\"\"Query the knowledge graph based on the question.\"\"\"\n",
    "        if not self.is_available():\n",
    "            return \"\"\n",
    "        \n",
    "        # Extract key terms from question for graph search\n",
    "        keywords = self._extract_keywords(question)\n",
    "        \n",
    "        graph_context = []\n",
    "        seen_nodes = set()\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            # Search for matching nodes\n",
    "            nodes = self.neo4j.search_nodes(keyword, limit=5)\n",
    "            \n",
    "            for node_data in nodes:\n",
    "                node_id = node_data.get(\"node_id\")\n",
    "                if node_id in seen_nodes:\n",
    "                    continue\n",
    "                seen_nodes.add(node_id)\n",
    "                \n",
    "                # Get node properties\n",
    "                node_props = node_data.get(\"n\", {})\n",
    "                labels = node_data.get(\"labels\", [])\n",
    "                \n",
    "                node_info = f\"[{'/'.join(labels)}] {node_props.get('name', 'Unknown')}\"\n",
    "                if node_props.get(\"description\"):\n",
    "                    node_info += f\": {node_props.get('description')}\"\n",
    "                graph_context.append(node_info)\n",
    "                \n",
    "                # Get relationships\n",
    "                relationships = self.neo4j.get_node_relationships(node_id, depth=1)\n",
    "                for rel_data in relationships[:5]:  # Limit relationships\n",
    "                    for rel in rel_data.get(\"relationships\", []):\n",
    "                        rel_info = f\"  -> {rel.get('type', 'RELATED')}\"\n",
    "                        if rel.get(\"props\", {}).get(\"description\"):\n",
    "                            rel_info += f\": {rel['props']['description']}\"\n",
    "                        graph_context.append(rel_info)\n",
    "        \n",
    "        if graph_context:\n",
    "            return \"Knowledge Graph Context:\\n\" + \"\\n\".join(graph_context[:20])  # Limit context size\n",
    "        return \"\"\n",
    "    \n",
    "    def _extract_keywords(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract keywords from text for graph search.\"\"\"\n",
    "        # Simple keyword extraction - remove common words\n",
    "        stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'what', 'who', \n",
    "                      'where', 'when', 'why', 'how', 'which', 'that', 'this', 'these',\n",
    "                      'those', 'it', 'its', 'in', 'on', 'at', 'to', 'for', 'of', 'and',\n",
    "                      'or', 'but', 'with', 'from', 'by', 'about', 'as', 'into', 'like',\n",
    "                      'through', 'after', 'over', 'between', 'out', 'against', 'during',\n",
    "                      'without', 'before', 'under', 'around', 'among', 'do', 'does', 'did',\n",
    "                      'can', 'could', 'would', 'should', 'may', 'might', 'must', 'shall'}\n",
    "        \n",
    "        # Tokenize and filter\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        keywords = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "        \n",
    "        # Return unique keywords, maintaining order\n",
    "        seen = set()\n",
    "        unique_keywords = []\n",
    "        for kw in keywords:\n",
    "            if kw not in seen:\n",
    "                seen.add(kw)\n",
    "                unique_keywords.append(kw)\n",
    "        \n",
    "        return unique_keywords[:10]  # Limit to top 10 keywords\n",
    "    \n",
    "    def get_graph_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Get statistics about the knowledge graph.\"\"\"\n",
    "        if not self.is_available():\n",
    "            return {\"nodes\": 0, \"relationships\": 0}\n",
    "        \n",
    "        node_count = self.neo4j.execute_query(\"MATCH (n) RETURN count(n) as count\")\n",
    "        rel_count = self.neo4j.execute_query(\"MATCH ()-[r]->() RETURN count(r) as count\")\n",
    "        \n",
    "        return {\n",
    "            \"nodes\": node_count[0][\"count\"] if node_count else 0,\n",
    "            \"relationships\": rel_count[0][\"count\"] if rel_count else 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classe HybridRAG\n",
    "C'est la classe principale qui orchestre le RAG Vectoriel et le RAG Graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRAG:\n",
    "    \"\"\"Hybrid RAG combining Vector Search (Qdrant) and Graph Search (Neo4j).\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        self.groq_model = os.getenv(\"GROQ_MODEL\", \"llama3-70b-8192\")\n",
    "        self.qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "        self.qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "        \n",
    "        if not self.groq_api_key or \"your_groq_api_key\" in self.groq_api_key:\n",
    "            raise ValueError(\"Please set a valid GROQ_API_KEY in your .env file\")\n",
    "            \n",
    "        self.llm = ChatGroq(\n",
    "            groq_api_key=self.groq_api_key, \n",
    "            model_name=self.groq_model,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        \n",
    "        # Initialize Qdrant Client\n",
    "        is_qdrant_configured = (\n",
    "            self.qdrant_url \n",
    "            and self.qdrant_api_key \n",
    "            and \"your_qdrant_url\" not in self.qdrant_url\n",
    "        )\n",
    "        \n",
    "        self.client = None\n",
    "        if is_qdrant_configured:\n",
    "            try:\n",
    "                self.client = QdrantClient(url=self.qdrant_url, api_key=self.qdrant_api_key)\n",
    "                self.client.get_collections()\n",
    "                print(\"\u2705 Connected to Qdrant Cloud\")\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f Failed to connect to Qdrant Cloud ({e}). Falling back to local memory.\")\n",
    "                self.client = None\n",
    "        \n",
    "        if not self.client:\n",
    "            print(\"\ud83d\udce6 Using local Qdrant (in-memory).\")\n",
    "            self.client = QdrantClient(location=\":memory:\")\n",
    "            \n",
    "        self.collection_name = \"hybrid_rag_collection\"\n",
    "        if not self.client.collection_exists(self.collection_name):\n",
    "            self.client.create_collection(\n",
    "                collection_name=self.collection_name,\n",
    "                vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    "            )\n",
    "            \n",
    "        self.vector_store = QdrantVectorStore(\n",
    "            client=self.client,\n",
    "            collection_name=self.collection_name,\n",
    "            embedding=self.embeddings,\n",
    "        )\n",
    "        \n",
    "        # Store retriever for later use\n",
    "        self.retriever = self.vector_store.as_retriever()\n",
    "        \n",
    "        # Initialize GraphRAG with shared LLM\n",
    "        self.graph_rag = GraphRAG(llm=self.llm)\n",
    "\n",
    "    def load_documents(self, file_paths: List[str]) -> List[Document]:\n",
    "        \"\"\"Load documents from various file formats.\"\"\"\n",
    "        documents = []\n",
    "        for file_path in file_paths:\n",
    "            ext = file_path.split('.')[-1].lower()\n",
    "            try:\n",
    "                if ext == 'pdf':\n",
    "                    loader = PyPDFLoader(file_path)\n",
    "                elif ext == 'txt':\n",
    "                    loader = TextLoader(file_path)\n",
    "                elif ext == 'csv':\n",
    "                    loader = CSVLoader(file_path)\n",
    "                elif ext == 'json':\n",
    "                    loader = JSONLoader(file_path, jq_schema='.', text_content=False)\n",
    "                else:\n",
    "                    continue\n",
    "                documents.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f Failed to load {file_path}: {e}\")\n",
    "        return documents\n",
    "\n",
    "    def ingest(self, file_paths: List[str], build_graph: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Ingest documents into both vector store and knowledge graph.\"\"\"\n",
    "        docs = self.load_documents(file_paths)\n",
    "        \n",
    "        # Vector store ingestion\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        self.vector_store.add_documents(splits)\n",
    "        \n",
    "        result = {\n",
    "            \"vector_chunks\": len(splits),\n",
    "            \"graph_entities\": 0,\n",
    "            \"graph_relations\": 0\n",
    "        }\n",
    "        \n",
    "        # Knowledge graph construction (if enabled and available)\n",
    "        if build_graph and self.graph_rag.is_available():\n",
    "            print(\"Building Knowledge Graph... This may take a moment.\")\n",
    "            graph_stats = self.graph_rag.build_graph(docs)\n",
    "            result[\"graph_entities\"] = graph_stats[\"entities\"]\n",
    "            result[\"graph_relations\"] = graph_stats[\"relations\"]\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def query(self, question: str, use_graph: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Query the Hybrid RAG system combining vector and graph retrieval.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Step 1: Vector retrieval\n",
    "            docs = self.retriever.invoke(question)\n",
    "            \n",
    "            if docs:\n",
    "                vector_context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "            else:\n",
    "                vector_context = \"No relevant documents found in vector store.\"\n",
    "            \n",
    "            # Step 2: Graph retrieval (if enabled)\n",
    "            graph_context = \"\"\n",
    "            if use_graph and self.graph_rag.is_available():\n",
    "                graph_context = self.graph_rag.query_graph(question)\n",
    "            \n",
    "            # Step 3: Combine contexts\n",
    "            if graph_context:\n",
    "                combined_context = f\"## Vector Search Results:\\n{vector_context}\\n\\n## {graph_context}\"\n",
    "            else:\n",
    "                combined_context = vector_context\n",
    "            \n",
    "            # Step 4: Build prompt\n",
    "            system_prompt = (\n",
    "                \"You are an intelligent assistant for question-answering tasks. \"\n",
    "                \"You have access to two types of information:\\n\"\n",
    "                \"1. Vector Search Results: Relevant text passages from documents\\n\"\n",
    "                \"2. Knowledge Graph Context: Entities and relationships extracted from documents\\n\\n\"\n",
    "                \"Use both sources to provide comprehensive, accurate answers. \"\n",
    "                \"If the information is insufficient, acknowledge what you don't know. \"\n",
    "                \"Be concise but thorough.\"\n",
    "                \"\\n\\nContext:\\n{context}\"\n",
    "            )\n",
    "            \n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system_prompt),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ])\n",
    "            \n",
    "            # Step 5: Generate response\n",
    "            chain = prompt | self.llm | StrOutputParser()\n",
    "            answer = chain.invoke({\"input\": question, \"context\": combined_context})\n",
    "            \n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            error_details = traceback.format_exc()\n",
    "            raise RuntimeError(f\"RAG Query failed: {e}\\nDetails:\\n{error_details}\")\n",
    "    \n",
    "    def get_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the status of all RAG components.\"\"\"\n",
    "        status = {\n",
    "            \"vector_store\": \"connected\",\n",
    "            \"graph_store\": \"connected\" if self.graph_rag.is_available() else \"disconnected\",\n",
    "            \"llm\": \"connected\"\n",
    "        }\n",
    "        \n",
    "        if self.graph_rag.is_available():\n",
    "            status[\"graph_stats\"] = self.graph_rag.get_graph_stats()\n",
    "        \n",
    "        return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. D\u00e9monstration\n",
    "Ici, nous initialisons le moteur HybridRAG, ing\u00e9rons un exemple de document et posons une question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HybridRAG...\n",
      "\u26a0\ufe0f Failed to connect to Qdrant Cloud (timed out). Falling back to local memory.\n",
      "\ud83d\udce6 Using local Qdrant (in-memory).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:neo4j.pool:Unable to retrieve routing information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f Failed to connect to Neo4j: Unable to retrieve routing information\n",
      "Status: {'vector_store': 'connected', 'graph_store': 'disconnected', 'llm': 'connected'}\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "print(\"Initializing HybridRAG...\")\n",
    "rag = HybridRAG()\n",
    "status = rag.get_status()\n",
    "print(\"Status:\", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation du fichier de donn\u00e9es GreenPower\n",
    "json_file = \"greenpower_data.json\"\n",
    "\n",
    "# Ingestion\n",
    "print(f\"Ingesting {json_file}...\")\n",
    "if os.path.exists(json_file):\n",
    "    result = rag.ingest([json_file])\n",
    "    print(\"Ingestion Result:\", result)\n",
    "else:\n",
    "    print(f\"Error: {json_file} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requ\u00eate\n",
    "question = \"Quels sont les produits de GreenPower et leurs sp\u00e9cifications ?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "response = rag.query(question)\n",
    "print(\"R\u00e9ponse:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}