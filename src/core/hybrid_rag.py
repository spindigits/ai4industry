import os
from dotenv import load_dotenv
from langchain_mistralai import ChatMistralAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from src.services.neo4j_query import Neo4jQuerier

load_dotenv()

class HybridRAG:
    """
    Routeur intelligent qui d√©cide d'utiliser:
    - RAG classique (Qdrant) pour questions simples/descriptives
    - RAG hybride (Qdrant + Neo4j) pour questions relationnelles/multi-hop
    """

    def __init__(self):
        self.llm = ChatMistralAI(
            model="mistral-small-latest",
            mistral_api_key=os.getenv("MISTRAL_API_KEY"),
            temperature=0
        )
        self.neo4j_querier = Neo4jQuerier()

    def set_model(self, model_name):
        """Met √† jour le mod√®le LLM utilis√©"""
        print(f"DEBUG: Switching LLM to {model_name}")
        self.llm = ChatMistralAI(
            model=model_name,
            mistral_api_key=os.getenv("MISTRAL_API_KEY"),
            temperature=0
        )

    def close(self):
        self.neo4j_querier.close()

    def classify_question(self, question):
        """
        Classifie la question pour d√©terminer la strat√©gie RAG appropri√©e.
        Retourne: "simple" ou "multi_hop"
        """
        # Keywords pour multi-hop (questions relationnelles/agr√©gations)
        multi_hop_keywords = [
            # Relations
            "quels √©v√©nements", "quels salons", "o√π", "qui",
            "liste", "lister", "tous les", "combien",
            # Agr√©gations
            "total", "somme", "moyenne", "maximum", "minimum",
            "√©conomis√©", "co2", "carbone",
            # Patterns multi-hop
            "vendus √†", "utilis√©s aux", "d√©ploy√©s √†", "pr√©sent√©s √†",
            "projets r&d", "recherche", "d√©veloppement",
            # Customer types
            "collectivit√©s", "entreprises", "particuliers",
            # Liens produit-√©v√©nement
            "festival", "salon", "avec", "par"
        ]

        question_lower = question.lower()

        # Check for multi-hop patterns
        multi_hop_score = sum(1 for keyword in multi_hop_keywords if keyword in question_lower)

        # Questions simples: description, sp√©cifications, prix
        simple_keywords = [
            "qu'est-ce que", "c'est quoi", "d√©cris", "describe",
            "caract√©ristiques", "specifications", "prix", "co√ªt",
            "comment fonctionne", "fonctionnement",
            "garantie", "warranty", "maintenance"
        ]

        # Keywords visuels (images)
        visual_keywords = [
            "image", "photo", "visuel", "figure", "graphique",
            ".jpg", ".png", ".jpeg", "illustration", "dessin"
        ]

        visual_score = sum(1 for keyword in visual_keywords if keyword in question_lower)
        simple_score = sum(1 for keyword in simple_keywords if keyword in question_lower)

        # Decision
        if visual_score > 0:
            return "visual"
        elif multi_hop_score > simple_score:
            return "multi_hop"
        else:
            return "simple"

    def _check_privacy(self, text: str) -> bool:
        """D√©tecte si le texte contient des donn√©es priv√©es (pr√©fixe 'private_')"""
        if not text:
            return False
        return "private_" in text

    def query_hybrid(self, question, vector_store):
        """
        RAG Hybride: Combine Qdrant (similarit√© s√©mantique) + Neo4j (relations)
        """
        privacy_alert = False

        # 1. R√©cup√©rer le contexte du graphe Neo4j
        print(f"DEBUG: Querying Neo4j for '{question}'...")
        graph_context_raw = self.neo4j_querier.get_graph_context_for_question(question)
        
        # Filtre confidentialit√© Graphe
        if self._check_privacy(str(graph_context_raw)):
            print("üîí Donn√©es priv√©es d√©tect√©es dans Neo4j (masqu√©es)")
            graph_context_raw = []
            graph_context = "Donn√©es relationnelles masqu√©es pour confidentialit√©."
            privacy_alert = True
        else:
            print(f"DEBUG: Neo4j Raw Context: {graph_context_raw}")
            graph_context = self.neo4j_querier.format_graph_context(graph_context_raw)

        # 2. R√©cup√©rer le contexte vectoriel de Qdrant
        print(f"DEBUG: Querying Qdrant...")
        retriever = vector_store.as_retriever(search_kwargs={"k": 3})
        vector_docs = retriever.invoke(question)
        
        # Filtre confidentialit√© Vectoriel
        safe_vector_docs = []
        for doc in vector_docs:
            if self._check_privacy(doc.page_content) or self._check_privacy(str(doc.metadata)):
                print(f"üîí Document priv√© filtr√©: {doc.metadata.get('source', 'unknown')}")
                privacy_alert = True
            else:
                safe_vector_docs.append(doc)
        
        vector_docs = safe_vector_docs
        vector_context = "\n\n".join([doc.page_content for doc in vector_docs])

        # 3. Cr√©er un prompt enrichi avec les deux contextes
        template = """Tu es un assistant expert sur GreenPower Solutions et leurs produits solaires autonomes.

Tu dois r√©pondre √† la question en utilisant DEUX sources de contexte:

1. CONTEXTE VECTORIEL (descriptions d√©taill√©es, documents):
{vector_context}

2. CONTEXTE GRAPHE (relations, agr√©gations, connexions):
{graph_context}

Utilise prioritairement le CONTEXTE GRAPHE pour les informations relationnelles (qui, o√π, combien, total, etc.)
et le CONTEXTE VECTORIEL pour les descriptions d√©taill√©es et sp√©cifications.

Si une information n'est pas pr√©sente dans les contextes, dis clairement que tu ne sais pas.
Ne fabrique pas de r√©ponses.

QUESTION: {question}

R√âPONSE:"""
        
        # Ajouter une instruction syst√®me si confidentialit√© activ√©e
        if privacy_alert:
            template += "\n\nNOTE IMPORTANTE: Certaines donn√©es ont √©t√© masqu√©es car elles contiennent la mention 'private_'. Indique-le √† l'utilisateur."

        prompt = ChatPromptTemplate.from_template(template)

        # 4. G√©n√©rer la r√©ponse
        chain = prompt | self.llm | StrOutputParser()

        answer = chain.invoke({
            "question": question,
            "vector_context": vector_context,
            "graph_context": graph_context if graph_context else "Aucune information relationnelle trouv√©e."
        })

        # Ajouter l'avertissement final
        if privacy_alert:
            answer += "\n\n‚ö†Ô∏è **Certaines donn√©es identifi√©es comme \"private_\" ont √©t√© masqu√©es pour des raisons de confidentialit√©.**"

        return {
            "answer": answer,
            "sources": {
                "vector_docs": vector_docs,
                "graph_context": graph_context_raw
            },
            "strategy": "hybrid"
        }

    def query_simple(self, question, vector_store):
        """
        RAG Simple: Utilise seulement Qdrant (similarit√© vectorielle)
        """
        privacy_alert = False

        retriever = vector_store.as_retriever(search_kwargs={"k": 3})
        vector_docs = retriever.invoke(question)
        
        # Filtre confidentialit√© Vectoriel
        safe_vector_docs = []
        for doc in vector_docs:
            if self._check_privacy(doc.page_content) or self._check_privacy(str(doc.metadata)):
                print(f"üîí Document priv√© filtr√©: {doc.metadata.get('source', 'unknown')}")
                privacy_alert = True
            else:
                safe_vector_docs.append(doc)
        
        vector_docs = safe_vector_docs
        vector_context = "\n\n".join([doc.page_content for doc in vector_docs])

        template = """Tu dois r√©pondre UNIQUEMENT √† partir des informations fournies dans le CONTEXTE ci-dessous.
Si une information n'est pas pr√©sente dans le CONTEXTE, dis clairement que tu ne sais pas.
Ne fabrique pas de r√©ponses.

CONTEXTE:
{context}

QUESTION: {question}

R√âPONSE:"""

        if privacy_alert:
            template += "\n\nNOTE IMPORTANTE: Certaines donn√©es ont √©t√© masqu√©es car elles contiennent la mention 'private_'. Indique-le √† l'utilisateur."

        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | self.llm | StrOutputParser()

        answer = chain.invoke({
            "question": question,
            "context": vector_context
        })

        # Ajouter l'avertissement final
        if privacy_alert:
            answer += "\n\n‚ö†Ô∏è **Certaines donn√©es identifi√©es comme \"private_\" ont √©t√© masqu√©es pour des raisons de confidentialit√©.**"

        return {
            "answer": answer,
            "sources": {
                "vector_docs": vector_docs
            },
            "strategy": "simple"
        }

    def query(self, question, vector_store, force_strategy=None):
        """
        Point d'entr√©e principal avec routage intelligent.

        Args:
            question: La question de l'utilisateur
            vector_store: Le vector store Qdrant
            force_strategy: "simple", "multi_hop", ou None (auto)

        Returns:
            dict avec answer, sources, strategy
        """
        # D√©terminer la strat√©gie
        if force_strategy:
            strategy = force_strategy
        else:
            strategy = self.classify_question(question)

        # Router vers la bonne m√©thode
        if strategy == "multi_hop":
            return self.query_hybrid(question, vector_store)
        elif strategy == "visual":
            # Le mode visuel utilise le RAG simple (vectoriel) mais avec une intention diff√©rente
            result = self.query_simple(question, vector_store)
            result["strategy"] = "visual"
            return result
        else:
            return self.query_simple(question, vector_store)

    def explain_routing(self, question):
        """
        Explique pourquoi une question est rout√©e vers simple ou multi-hop
        """
        strategy = self.classify_question(question)

        if strategy == "multi_hop":
            explanation = """
Cette question n√©cessite un RAG HYBRIDE (Qdrant + Neo4j) car elle implique:
- Des relations entre entit√©s (produits, √©v√©nements, salons)
- Des agr√©gations (total, somme, liste compl√®te)
- Du multi-hop reasoning (suivre des chemins dans le graphe)

Le graphe Neo4j va permettre de:
- Naviguer entre les n≈ìuds li√©s
- Calculer des agr√©gations
- Trouver des patterns complexes
"""
        elif strategy == "visual":
            explanation = """
Cette question concerne une **IMAGE** ou un contenu visuel.
Le syst√®me va utiliser les descriptions enrichies g√©n√©r√©es par **Pixtral (Vision LLM)**.

- Recherche des chunks d√©crivant les images (nom du fichier, description visuelle).
- Utilisation de la recherche vectorielle pour trouver l'image la plus pertinente.
"""
        else:
            explanation = """
Cette question peut √™tre trait√© avec un RAG SIMPLE (Qdrant uniquement) car elle demande:
- Une description ou sp√©cification
- Des informations contenues dans les documents
- Pas de relations complexes ou agr√©gations

La recherche vectorielle suffit pour trouver la r√©ponse.
"""

        return {
            "strategy": strategy,
            "explanation": explanation.strip()
        }


class QueryExamples:
    """Exemples de questions pour tester le syst√®me"""

    SIMPLE_QUESTIONS = [
        "Qu'est-ce que le produit GreenPower Max?",
        "Quelles sont les caract√©ristiques du PG-U01?",
        "Quel est le prix du GreenPower Compact?",
        "Comment fonctionne un g√©n√©rateur solaire autonome?",
        "Quelle est la capacit√© de la batterie du PG-M01?",
        "Quels sont les avantages de la location?",
    ]

    MULTI_HOP_QUESTIONS = [
        "Quels √©v√©nements ont utilis√© des produits vendus √† Pollutec Paris?",
        "Quel est le CO2 total √©conomis√© par le produit PG-M01?",
        "Quels salons ont g√©n√©r√© le plus de revenus avec les collectivit√©s?",
        "Quels projets R&D visent les produits utilis√©s aux festivals?",
        "Quels produits avec batteries LiFePO4 ont √©t√© vendus?",
        "Dans quels salons le PG-U01 a-t-il √©t√© vendu?",
    ]
