{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d255999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f9bf820",
   "metadata": {},
   "source": [
    "1. Setup Neo4j Aura (vectoriel)\n",
    "2. Chargement documents GreenPower via Gradio\n",
    "3. Chunking + Embeddings (sentence-transformers)\n",
    "4. Stockage Neo4j vector index\n",
    "5. RAG pipeline : query ‚Üí retrieval ‚Üí Mistral\n",
    "6. Interface Gradio interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ac835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0 - Test imports AVANT de lancer Gradio\n",
    "try:\n",
    "    from langchain.schema import HumanMessage\n",
    "    print(\"‚úì langchain.schema OK\")\n",
    "except:\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    print(\"‚úì langchain_core.messages OK\")\n",
    "!pip install langchain-mistralai langchain qdrant-client gradio sentence-transformers pypdf\n",
    "!pip install -r requirements.txt --force-reinstall\n",
    "!pip install dotenv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5158256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import gradio as gr\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Fix import\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import uuid\n",
    "from typing import List\n",
    "import pypdf\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "154054f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path('.env')\n",
    "if env_path.exists():\n",
    "    with open(env_path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                os.environ[key.strip()] = value.strip()\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "QDRANT_URL = os.getenv('QDRANT_URL', 'URL')  # Use :memory: for local or cloud URL\n",
    "QDRANT_API_KEY = os.getenv('QDRANT_API_KEY', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f7e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agaragar\\AppData\\Local\\Temp\\ipykernel_19460\\3474286160.py:5: UserWarning: Failed to obtain server version. Unable to check client-server compatibility. Set check_compatibility=False to skip version check.\n",
      "  qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "llm = ChatMistralAI(model='mistral-small-latest', mistral_api_key=MISTRAL_API_KEY, temperature=0.7)\n",
    "\n",
    "qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "COLLECTION_NAME = \"greenpower_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d720f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Collection 'greenpower_docs' existe d√©j√†\n"
     ]
    }
   ],
   "source": [
    "# Create collection\n",
    "try:\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    "    )\n",
    "    print(f\"‚úì Collection '{COLLECTION_NAME}' cr√©√©e\")\n",
    "except:\n",
    "    print(f\"‚úì Collection '{COLLECTION_NAME}' existe d√©j√†\")\n",
    "\n",
    "# Cell 5\n",
    "def extract_text(file_path: str) -> str:\n",
    "    ext = Path(file_path).suffix.lower()\n",
    "    if ext == '.pdf':\n",
    "        with open(file_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            return '\\n'.join([page.extract_text() for page in reader.pages])\n",
    "    elif ext == '.docx':\n",
    "        doc = docx.Document(file_path)\n",
    "        return '\\n'.join([p.text for p in doc.paragraphs])\n",
    "    elif ext == '.txt':\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_documents(files):\n",
    "    if not files:\n",
    "        return \"‚ùå Aucun fichier\"\n",
    "    \n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        uploaded_count = 0\n",
    "        \n",
    "        for file in files:\n",
    "            # FIX: Gradio renvoie un objet, pas juste un nom\n",
    "            file_path = file.name if hasattr(file, 'name') else file\n",
    "            text = extract_text(file_path)\n",
    "            \n",
    "            if not text:\n",
    "                continue\n",
    "                \n",
    "            chunks = text_splitter.split_text(text)\n",
    "            \n",
    "            points = []\n",
    "            for chunk in chunks:\n",
    "                vector = embeddings.embed_query(chunk)\n",
    "                point = PointStruct(\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    vector=vector,\n",
    "                    payload={\"text\": chunk, \"source\": Path(file_path).name}\n",
    "                )\n",
    "                points.append(point)\n",
    "            \n",
    "            qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "            uploaded_count += len(chunks)\n",
    "        \n",
    "        return f\"‚úì {uploaded_count} chunks upload√©s depuis {len(files)} fichiers dans Qdrant\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erreur: {str(e)}\"\n",
    "\n",
    "# Cell 7 - Fix search_and_answer\n",
    "def search_and_answer(question: str, top_k: int = 3) -> str:\n",
    "    if not question or question.strip() == \"\":\n",
    "        return \"‚ùå Veuillez poser une question\"\n",
    "    \n",
    "    try:\n",
    "        query_vector = embeddings.embed_query(question)\n",
    "        \n",
    "        results = qdrant_client.search(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_vector=query_vector,\n",
    "            limit=top_k\n",
    "        )\n",
    "        \n",
    "        if not results:\n",
    "            return \"‚ùå Aucun document trouv√© dans la base\"\n",
    "        \n",
    "        context = \"\\n\\n\".join([hit.payload[\"text\"] for hit in results])\n",
    "        \n",
    "        prompt = f\"\"\"Contexte GreenPower:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "R√©ponds en te basant uniquement sur le contexte fourni.\"\"\"\n",
    "        \n",
    "        # FIX import HumanMessage\n",
    "        try:\n",
    "            from langchain.schema import HumanMessage\n",
    "        except:\n",
    "            from langchain_core.messages import HumanMessage\n",
    "            \n",
    "        response = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "        \n",
    "        sources = \"\\n\".join([f\"- {hit.payload['source']} (score: {hit.score:.2f})\" for hit in results])\n",
    "        \n",
    "        return f\"{response}\\n\\n**Sources:**\\n{sources}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erreur: {str(e)}\"\n",
    "\n",
    "# Cell 8 - Interface Gradio FIX√âE\n",
    "with gr.Blocks(title=\"GreenPower RAG\") as demo:\n",
    "    gr.Markdown(\"# üå± GreenPower RAG System\")\n",
    "    \n",
    "    with gr.Tab(\"üì§ Upload Documents\"):\n",
    "        file_input = gr.File(\n",
    "            file_count=\"multiple\", \n",
    "            label=\"Documents GreenPower (PDF, DOCX, TXT)\",\n",
    "            file_types=[\".pdf\", \".docx\", \".txt\"]\n",
    "        )\n",
    "        upload_btn = gr.Button(\"Upload\", variant=\"primary\")\n",
    "        upload_output = gr.Textbox(label=\"Status\", lines=3)\n",
    "        \n",
    "        upload_btn.click(\n",
    "            fn=upload_documents, \n",
    "            inputs=[file_input], \n",
    "            outputs=[upload_output]\n",
    "        )\n",
    "    \n",
    "    with gr.Tab(\"üí¨ Ask Questions\"):\n",
    "        question_input = gr.Textbox(\n",
    "            label=\"Question\", \n",
    "            placeholder=\"Ex: Quel est le prix du GreenPower Max?\",\n",
    "            lines=2\n",
    "        )\n",
    "        top_k_slider = gr.Slider(\n",
    "            minimum=1, \n",
    "            maximum=10, \n",
    "            value=3, \n",
    "            step=1, \n",
    "            label=\"Nombre de chunks √† r√©cup√©rer\"\n",
    "        )\n",
    "        ask_btn = gr.Button(\"Poser la question\", variant=\"primary\")\n",
    "        answer_output = gr.Markdown(label=\"R√©ponse\")\n",
    "        \n",
    "        ask_btn.click(\n",
    "            fn=search_and_answer, \n",
    "            inputs=[question_input, top_k_slider], \n",
    "            outputs=[answer_output]\n",
    "        )\n",
    "\n",
    "demo.launch(server_name=\"127.0.0.1\", server_port=7860, share=False, debug=Tru99 \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    uploaded_count = 0\n",
    "    \n",
    "    for file in files:\n",
    "        text = extract_text(file.name)\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        \n",
    "        points = []\n",
    "        for chunk in chunks:\n",
    "            vector = embeddings.embed_query(chunk)\n",
    "            point = PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=vector,\n",
    "                payload={\"text\": chunk, \"source\": Path(file.name).name}\n",
    "            )\n",
    "            points.append(point)\n",
    "        \n",
    "        qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "        uploaded_count += len(chunks)\n",
    "    \n",
    "    return f\"‚úì {uploaded_count} chunks upload√©s depuis {len(files)} fichiers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "327b72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "def search_and_answer(question: str, top_k: int = 3) -> str:\n",
    "    query_vector = embeddings.embed_query(question)\n",
    "    \n",
    "    results = qdrant_client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k\n",
    "    )\n",
    "    \n",
    "    if not results:\n",
    "        return \"‚ùå Aucun document trouv√©\"\n",
    "    \n",
    "    context = \"\\n\\n\".join([hit.payload[\"text\"] for hit in results])\n",
    "    \n",
    "    prompt = f\"\"\"Contexte GreenPower:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "R√©ponds en te basant uniquement sur le contexte fourni.\"\"\"\n",
    "    \n",
    "    from langchain.schema import HumanMessage\n",
    "    response = llm.invoke([HumanMessage(content=prompt)]).content\n",
    "    \n",
    "    sources = \"\\n\".join([f\"- {hit.payload['source']} (score: {hit.score:.2f})\" for hit in results])\n",
    "    \n",
    "    return f\"{response}\\n\\n**Sources:**\\n{sources}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b774a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7990\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7990/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 1034, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\agaragar\\AppData\\Local\\Temp\\ipykernel_19460\\4163106989.py\", line 23, in upload_documents\n",
      "    qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py\", line 938, in upsert\n",
      "    return self._client.upsert(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py\", line 1121, in upsert\n",
      "    http_result = self.openapi_client.points_api.upsert_points(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py\", line 994, in upsert_points\n",
      "    return self._build_for_upsert_points(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py\", line 515, in _build_for_upsert_points\n",
      "    return self.api_client.request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 95, in request\n",
      "    return self.send(request, type_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 130, in send\n",
      "    raise UnexpectedResponse.for_response(response)\n",
      "qdrant_client.http.exceptions.UnexpectedResponse: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b'404 page not found\\n'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 1034, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\agaragar\\AppData\\Local\\Temp\\ipykernel_19460\\4163106989.py\", line 23, in upload_documents\n",
      "    qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py\", line 938, in upsert\n",
      "    return self._client.upsert(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py\", line 1121, in upsert\n",
      "    http_result = self.openapi_client.points_api.upsert_points(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py\", line 994, in upsert_points\n",
      "    return self._build_for_upsert_points(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py\", line 515, in _build_for_upsert_points\n",
      "    return self.api_client.request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 95, in request\n",
      "    return self.send(request, type_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 130, in send\n",
      "    raise UnexpectedResponse.for_response(response)\n",
      "qdrant_client.http.exceptions.UnexpectedResponse: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b'404 page not found\\n'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 1034, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\agaragar\\AppData\\Local\\Temp\\ipykernel_19460\\335000091.py\", line 5, in search_and_answer\n",
      "    results = qdrant_client.search(\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'QdrantClient' object has no attribute 'search'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 1034, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\agaragar\\AppData\\Local\\Temp\\ipykernel_19460\\335000091.py\", line 5, in search_and_answer\n",
      "    results = qdrant_client.search(\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'QdrantClient' object has no attribute 'search'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 1034, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\agaragar\\AppData\\Local\\Temp\\ipykernel_19460\\4163106989.py\", line 23, in upload_documents\n",
      "    qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py\", line 938, in upsert\n",
      "    return self._client.upsert(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py\", line 1121, in upsert\n",
      "    http_result = self.openapi_client.points_api.upsert_points(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py\", line 994, in upsert_points\n",
      "    return self._build_for_upsert_points(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\points_api.py\", line 515, in _build_for_upsert_points\n",
      "    return self.api_client.request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 95, in request\n",
      "    return self.send(request, type_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\agaragar\\Documents\\00 CLIENTS\\0000 VALLUP\\00 MENSAFLOW\\00 CNAM\\UseCase\\Jupyter\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 130, in send\n",
      "    raise UnexpectedResponse.for_response(response)\n",
      "qdrant_client.http.exceptions.UnexpectedResponse: Unexpected Response: 404 (Not Found)\n",
      "Raw response content:\n",
      "b'404 page not found\\n'\n"
     ]
    }
   ],
   "source": [
    "# Cell 8\n",
    "# Gradio Interface\n",
    "with gr.Blocks(title=\"GreenPower RAG\") as demo:\n",
    "    gr.Markdown(\"# üå± GreenPower RAG System\")\n",
    "    \n",
    "    with gr.Tab(\"üì§ Upload Documents\"):\n",
    "        file_input = gr.File(file_count=\"multiple\", label=\"Documents GreenPower (PDF, DOCX, TXT)\")\n",
    "        upload_btn = gr.Button(\"Upload\")\n",
    "        upload_output = gr.Textbox(label=\"Status\")\n",
    "        upload_btn.click(upload_documents, inputs=file_input, outputs=upload_output)\n",
    "    \n",
    "    with gr.Tab(\"üí¨ Ask Questions\"):\n",
    "        question_input = gr.Textbox(label=\"Question\", placeholder=\"Posez une question sur GreenPower...\")\n",
    "        top_k_slider = gr.Slider(1, 10, value=3, step=1, label=\"Nombre de chunks √† r√©cup√©rer\")\n",
    "        ask_btn = gr.Button(\"Ask\")\n",
    "        answer_output = gr.Markdown(label=\"R√©ponse\")\n",
    "        ask_btn.click(search_and_answer, inputs=[question_input, top_k_slider], outputs=answer_output)\n",
    "\n",
    "demo.launch(server_name=\"127.0.0.1\", server_port=7990, share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
